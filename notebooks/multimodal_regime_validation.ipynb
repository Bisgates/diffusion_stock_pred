{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Regime Distribution Validation (Real Data)\n",
    "\n",
    "## Objective\n",
    "Test whether the diffusion model can learn **different probability distributions** for **different market conditions** using **real stock data patterns**.\n",
    "\n",
    "## Experiment Design\n",
    "\n",
    "We extract real patterns from `data_1s/` and group them by their subsequent 30-second returns:\n",
    "\n",
    "| Regime | Description | Target Distribution |\n",
    "|--------|-------------|--------------------|\n",
    "| **Bullish** | Patterns preceding positive moves | ~80% positive returns |\n",
    "| **Bearish** | Patterns preceding negative moves | ~80% negative returns |\n",
    "| **Neutral** | Patterns with small subsequent moves | ~50/50, small magnitude |\n",
    "\n",
    "## Key Differences from Synthetic Data\n",
    "- Return magnitudes are realistic (~0.2% std for 30s horizon)\n",
    "- Condition patterns extracted from actual market data\n",
    "- Feature distributions match real trading dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "import gc\n",
    "\n",
    "from src.models.model import StockDiffusionModel, ModelConfig\n",
    "from src.data.loader import StockDataLoader, DataConfig\n",
    "from src.data.preprocessing import DataPreprocessor, PreprocessConfig\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device setup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Real Market Patterns\n",
    "\n",
    "We load actual stock data and categorize sequences by their outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SEQ_LENGTH = 120   # 120 seconds of history\n",
    "HORIZON = 30       # 30 seconds prediction horizon\n",
    "N_FEATURES = 4     # log_return, volatility_5s, spread, volume_zscore\n",
    "FEATURE_NAMES = ['log_return', 'volatility_5s', 'spread', 'volume_zscore']\n",
    "\n",
    "# Data paths\n",
    "data_dir = project_root / 'data_1s'\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Sequence length: {SEQ_LENGTH}s\")\n",
    "print(f\"Prediction horizon: {HORIZON}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_real_patterns(\n",
    "    data_dir: Path,\n",
    "    n_dates: int = 15,\n",
    "    n_symbols_per_date: int = 30,\n",
    "    seq_length: int = 120,\n",
    "    horizon: int = 30,\n",
    "    sample_stride: int = 30,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[Dict[str, np.ndarray], Dict[str, np.ndarray], float]:\n",
    "    \"\"\"\n",
    "    Extract real market patterns and categorize by outcome.\n",
    "    \n",
    "    Returns:\n",
    "        conditions: Dict mapping regime -> array of condition sequences\n",
    "        returns: Dict mapping regime -> array of target returns\n",
    "        threshold: Return threshold used for categorization\n",
    "    \"\"\"\n",
    "    config = DataConfig(data_dir=data_dir)\n",
    "    loader = StockDataLoader(config)\n",
    "    preprocessor = DataPreprocessor(PreprocessConfig())\n",
    "    \n",
    "    dates = loader.get_available_dates()[:n_dates]\n",
    "    if verbose:\n",
    "        print(f\"Processing {len(dates)} dates...\")\n",
    "    \n",
    "    all_sequences = []  # List of (condition, return)\n",
    "    \n",
    "    for date in tqdm(dates, disable=not verbose, desc=\"Extracting patterns\"):\n",
    "        symbols = loader.get_available_symbols(date)[:n_symbols_per_date]\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            df = loader.load_symbol_day(symbol, date, filter_market_hours=True)\n",
    "            if df is None or len(df) < seq_length + horizon + 10:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                processed, valid = preprocessor.process_day(df)\n",
    "                \n",
    "                # Extract sequences\n",
    "                for i in range(0, len(processed) - seq_length - horizon, sample_stride):\n",
    "                    if not valid[i:i + seq_length + horizon].all():\n",
    "                        continue\n",
    "                    \n",
    "                    # Condition: feature sequence\n",
    "                    cond = processed[FEATURE_NAMES].iloc[i:i + seq_length].values\n",
    "                    \n",
    "                    # Target: forward return\n",
    "                    p_now = df['close'].iloc[i + seq_length]\n",
    "                    p_future = df['close'].iloc[i + seq_length + horizon]\n",
    "                    ret = (p_future / p_now) - 1\n",
    "                    \n",
    "                    if np.isfinite(cond).all() and np.isfinite(ret):\n",
    "                        all_sequences.append((cond.astype(np.float32), float(ret)))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nExtracted {len(all_sequences):,} sequences\")\n",
    "    \n",
    "    # Analyze return distribution\n",
    "    returns_all = np.array([r for _, r in all_sequences])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nReturn distribution:\")\n",
    "        print(f\"  Mean: {returns_all.mean()*100:.4f}%\")\n",
    "        print(f\"  Std:  {returns_all.std()*100:.4f}%\")\n",
    "        print(f\"  5th percentile: {np.percentile(returns_all, 5)*100:.4f}%\")\n",
    "        print(f\"  95th percentile: {np.percentile(returns_all, 95)*100:.4f}%\")\n",
    "    \n",
    "    # Categorize by return magnitude (top/bottom ~20%)\n",
    "    threshold = np.percentile(np.abs(returns_all), 60)\n",
    "    \n",
    "    bullish = [(c, r) for c, r in all_sequences if r > threshold]\n",
    "    bearish = [(c, r) for c, r in all_sequences if r < -threshold]\n",
    "    neutral = [(c, r) for c, r in all_sequences if abs(r) <= threshold]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nCategorization (threshold: Â±{threshold*100:.4f}%):\")\n",
    "        print(f\"  Bullish: {len(bullish):,} samples, mean={np.mean([r for _,r in bullish])*100:.4f}%\")\n",
    "        print(f\"  Bearish: {len(bearish):,} samples, mean={np.mean([r for _,r in bearish])*100:.4f}%\")\n",
    "        print(f\"  Neutral: {len(neutral):,} samples, mean={np.mean([r for _,r in neutral])*100:.4f}%\")\n",
    "    \n",
    "    # Return organized data\n",
    "    conditions = {\n",
    "        'bullish': np.stack([c for c, _ in bullish]),\n",
    "        'bearish': np.stack([c for c, _ in bearish]),\n",
    "        'neutral': np.stack([c for c, _ in neutral])\n",
    "    }\n",
    "    \n",
    "    returns = {\n",
    "        'bullish': np.array([r for _, r in bullish], dtype=np.float32),\n",
    "        'bearish': np.array([r for _, r in bearish], dtype=np.float32),\n",
    "        'neutral': np.array([r for _, r in neutral], dtype=np.float32)\n",
    "    }\n",
    "    \n",
    "    return conditions, returns, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patterns from real data\n",
    "conditions, returns, threshold = extract_real_patterns(\n",
    "    data_dir=data_dir,\n",
    "    n_dates=20,            # Use 20 days\n",
    "    n_symbols_per_date=40, # 40 stocks per day\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    horizon=HORIZON,\n",
    "    sample_stride=20,      # Sample every 20 seconds\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the extracted patterns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "regimes = ['bullish', 'bearish', 'neutral']\n",
    "colors = {'bullish': 'green', 'bearish': 'red', 'neutral': 'gray'}\n",
    "titles = ['Bullish (r > threshold)', 'Bearish (r < -threshold)', 'Neutral (small |r|)']\n",
    "\n",
    "for idx, (regime, title) in enumerate(zip(regimes, titles)):\n",
    "    conds = conditions[regime]\n",
    "    rets = returns[regime]\n",
    "    color = colors[regime]\n",
    "    \n",
    "    # Top row: Average condition pattern\n",
    "    ax = axes[0, idx]\n",
    "    mean_cond = conds.mean(axis=0)\n",
    "    for i, feat in enumerate(FEATURE_NAMES):\n",
    "        ax.plot(mean_cond[:, i], label=feat, alpha=0.8)\n",
    "    ax.set_title(f'{title}\\nAverage Condition (n={len(conds):,})')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Feature Value')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom row: Return distribution\n",
    "    ax = axes[1, idx]\n",
    "    ax.hist(rets * 100, bins=50, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5)\n",
    "    ax.axvline(x=rets.mean() * 100, color='blue', linestyle='-', linewidth=2, \n",
    "               label=f'Mean: {rets.mean()*100:.3f}%')\n",
    "    ax.set_title(f'Return Distribution')\n",
    "    ax.set_xlabel('Return (%)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nReturn threshold: Â±{threshold*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Regime-Specific Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealRegimeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for a specific market regime using real data patterns.\n",
    "    \n",
    "    Uses a representative condition pattern for each regime,\n",
    "    paired with the actual return distribution from that regime.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        regime: str,\n",
    "        regime_conditions: np.ndarray,\n",
    "        regime_returns: np.ndarray,\n",
    "        n_samples: int = 2000,\n",
    "        use_mean_pattern: bool = True\n",
    "    ):\n",
    "        self.regime = regime\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        if use_mean_pattern:\n",
    "            # Use mean pattern as representative condition\n",
    "            self.condition = regime_conditions.mean(axis=0).astype(np.float32)\n",
    "        else:\n",
    "            # Use a random pattern\n",
    "            idx = np.random.randint(len(regime_conditions))\n",
    "            self.condition = regime_conditions[idx].astype(np.float32)\n",
    "        \n",
    "        # Sample targets from real distribution (with replacement)\n",
    "        indices = np.random.choice(len(regime_returns), size=n_samples, replace=True)\n",
    "        self.targets = regime_returns[indices].astype(np.float32)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            'input': torch.from_numpy(self.condition.copy()),\n",
    "            'target': torch.tensor([self.targets[idx]], dtype=torch.float32)\n",
    "        }\n",
    "    \n",
    "    def get_condition_tensor(self) -> torch.Tensor:\n",
    "        return torch.from_numpy(self.condition.copy())\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        return {\n",
    "            'regime': self.regime,\n",
    "            'n_samples': self.n_samples,\n",
    "            'mean': self.targets.mean(),\n",
    "            'std': self.targets.std(),\n",
    "            'pct_positive': (self.targets > 0).mean() * 100\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for each regime\n",
    "N_SAMPLES_PER_REGIME = 3000\n",
    "\n",
    "datasets = {}\n",
    "for regime in ['bullish', 'bearish', 'neutral']:\n",
    "    datasets[regime] = RealRegimeDataset(\n",
    "        regime=regime,\n",
    "        regime_conditions=conditions[regime],\n",
    "        regime_returns=returns[regime],\n",
    "        n_samples=N_SAMPLES_PER_REGIME,\n",
    "        use_mean_pattern=True\n",
    "    )\n",
    "\n",
    "# Print statistics\n",
    "print(\"Dataset Statistics (Real Data):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Regime':<12} {'Samples':<10} {'Mean':>12} {'Std':>10} {'%Positive':>12}\")\n",
    "print(\"-\" * 70)\n",
    "for regime, ds in datasets.items():\n",
    "    stats = ds.get_stats()\n",
    "    print(f\"{stats['regime']:<12} {stats['n_samples']:<10} {stats['mean']*100:>+11.4f}% {stats['std']*100:>9.4f}% {stats['pct_positive']:>11.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare condition patterns between regimes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for i, feat in enumerate(FEATURE_NAMES):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    for regime in ['bullish', 'bearish', 'neutral']:\n",
    "        pattern = datasets[regime].condition[:, i]\n",
    "        ax.plot(pattern, color=colors[regime], label=regime.capitalize(), alpha=0.8, linewidth=2)\n",
    "    ax.set_title(f'Feature: {feat}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Condition Patterns by Regime (Real Data)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize and Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalization statistics\n",
    "all_conditions = np.concatenate([conditions[r] for r in regimes], axis=0)\n",
    "norm_mean = all_conditions.reshape(-1, N_FEATURES).mean(axis=0)\n",
    "norm_std = all_conditions.reshape(-1, N_FEATURES).std(axis=0) + 1e-8\n",
    "\n",
    "print(\"Normalization statistics:\")\n",
    "for i, feat in enumerate(FEATURE_NAMES):\n",
    "    print(f\"  {feat}: mean={norm_mean[i]:.6f}, std={norm_std[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedDataset(Dataset):\n",
    "    \"\"\"Wrapper that normalizes conditions.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dataset: RealRegimeDataset, mean: np.ndarray, std: np.ndarray):\n",
    "        self.base = base_dataset\n",
    "        self.mean = mean.astype(np.float32)\n",
    "        self.std = std.astype(np.float32)\n",
    "        self.normalized_condition = (self.base.condition - self.mean) / self.std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input': torch.from_numpy(self.normalized_condition.copy()),\n",
    "            'target': torch.tensor([self.base.targets[idx]], dtype=torch.float32)\n",
    "        }\n",
    "    \n",
    "    def get_condition_tensor(self):\n",
    "        return torch.from_numpy(self.normalized_condition.copy())\n",
    "    \n",
    "    @property\n",
    "    def regime(self):\n",
    "        return self.base.regime\n",
    "    \n",
    "    @property\n",
    "    def targets(self):\n",
    "        return self.base.targets\n",
    "\n",
    "\n",
    "# Create normalized datasets\n",
    "norm_datasets = {\n",
    "    regime: NormalizedDataset(ds, norm_mean, norm_std)\n",
    "    for regime, ds in datasets.items()\n",
    "}\n",
    "\n",
    "print(\"Created normalized datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine for training\n",
    "combined_dataset = ConcatDataset(list(norm_datasets.values()))\n",
    "print(f\"Combined dataset size: {len(combined_dataset)} samples\")\n",
    "\n",
    "# Create model\n",
    "model_config = ModelConfig(\n",
    "    encoder_type=\"transformer\",\n",
    "    input_features=N_FEATURES,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    encoder_dim=64,\n",
    "    encoder_layers=3,\n",
    "    encoder_heads=4,\n",
    "    diffusion_steps=500,\n",
    "    noise_schedule=\"cosine\",\n",
    "    prediction_type=\"epsilon\",\n",
    "    denoiser_type=\"mlp\",\n",
    "    denoising_hidden_dim=128,\n",
    "    denoising_blocks=4,\n",
    "    time_embedding_dim=64,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "model = StockDiffusionModel(model_config).to(device)\n",
    "print(f\"Model parameters: {model.get_num_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset,\n",
    "    epochs: int = 200,\n",
    "    batch_size: int = 128,\n",
    "    learning_rate: float = 3e-4,\n",
    "    device: torch.device = device\n",
    ") -> List[float]:\n",
    "    \"\"\"Train the diffusion model.\"\"\"\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=learning_rate/20)\n",
    "    \n",
    "    losses = []\n",
    "    model.train()\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "    for epoch in pbar:\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            x_seq = batch['input'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_seq, target)\n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        losses.append(avg_loss)\n",
    "        pbar.set_postfix({'loss': f'{avg_loss:.6f}', 'lr': f'{scheduler.get_last_lr()[0]:.2e}'})\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "EPOCHS = 250\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "print(f\"Training: {EPOCHS} epochs, batch_size={BATCH_SIZE}, lr={LEARNING_RATE}\")\n",
    "print(f\"Total samples: {len(combined_dataset)}\\n\")\n",
    "\n",
    "losses = train_model(model, combined_dataset, epochs=EPOCHS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal loss: {losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample from Each Regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_regime(\n",
    "    model: nn.Module,\n",
    "    condition: torch.Tensor,\n",
    "    n_samples: int = 500,\n",
    "    use_ddim: bool = True,\n",
    "    ddim_steps: int = 50,\n",
    "    device: torch.device = device\n",
    ") -> np.ndarray:\n",
    "    model.eval()\n",
    "    condition = condition.unsqueeze(0).to(device).expand(n_samples, -1, -1)\n",
    "    samples = model.sample(condition, num_samples=1, use_ddim=use_ddim, ddim_steps=ddim_steps)\n",
    "    return samples.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from each regime\n",
    "N_INFERENCE_SAMPLES = 500\n",
    "\n",
    "print(f\"Sampling {N_INFERENCE_SAMPLES} predictions per regime...\\n\")\n",
    "\n",
    "predictions = {}\n",
    "for regime, ds in norm_datasets.items():\n",
    "    condition = ds.get_condition_tensor()\n",
    "    preds = sample_regime(model, condition, n_samples=N_INFERENCE_SAMPLES)\n",
    "    predictions[regime] = preds\n",
    "    \n",
    "    print(f\"{regime.capitalize()}:\")\n",
    "    print(f\"  GT:   mean={ds.targets.mean()*100:+.4f}%, std={ds.targets.std()*100:.4f}%, pos={(ds.targets>0).mean()*100:.1f}%\")\n",
    "    print(f\"  Pred: mean={preds.mean()*100:+.4f}%, std={preds.std()*100:.4f}%, pos={(preds>0).mean()*100:.1f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GT vs predictions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "for idx, regime in enumerate(regimes):\n",
    "    ds = norm_datasets[regime]\n",
    "    preds = predictions[regime]\n",
    "    color = colors[regime]\n",
    "    \n",
    "    # Top: Ground truth\n",
    "    ax = axes[0, idx]\n",
    "    ax.hist(ds.targets * 100, bins=50, color=color, alpha=0.7, edgecolor='black', density=True)\n",
    "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5)\n",
    "    ax.axvline(x=ds.targets.mean() * 100, color='blue', linestyle='-', linewidth=2, \n",
    "               label=f'Mean: {ds.targets.mean()*100:+.4f}%')\n",
    "    ax.set_title(f'{regime.capitalize()}\\nGround Truth', fontsize=12)\n",
    "    ax.set_xlabel('Return (%)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bottom: Predictions\n",
    "    ax = axes[1, idx]\n",
    "    ax.hist(preds * 100, bins=50, color=color, alpha=0.7, edgecolor='black', density=True)\n",
    "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5)\n",
    "    ax.axvline(x=preds.mean() * 100, color='blue', linestyle='-', linewidth=2, \n",
    "               label=f'Pred: {preds.mean()*100:+.4f}%')\n",
    "    ax.axvline(x=ds.targets.mean() * 100, color='red', linestyle=':', linewidth=2, \n",
    "               label=f'GT: {ds.targets.mean()*100:+.4f}%')\n",
    "    ax.set_title(f'{regime.capitalize()}\\nPredictions (n={N_INFERENCE_SAMPLES})', fontsize=12)\n",
    "    ax.set_xlabel('Return (%)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'outputs' / 'real_regime_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved to outputs/real_regime_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay all regimes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "for regime in regimes:\n",
    "    ds = norm_datasets[regime]\n",
    "    ax.hist(ds.targets * 100, bins=50, color=colors[regime], alpha=0.5, \n",
    "            label=f\"{regime.capitalize()} (Î¼={ds.targets.mean()*100:+.3f}%)\", density=True)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5)\n",
    "ax.set_title('Ground Truth', fontsize=12)\n",
    "ax.set_xlabel('Return (%)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "for regime in regimes:\n",
    "    preds = predictions[regime]\n",
    "    ax.hist(preds * 100, bins=50, color=colors[regime], alpha=0.5, \n",
    "            label=f\"{regime.capitalize()} (Î¼={preds.mean()*100:+.3f}%)\", density=True)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=1.5)\n",
    "ax.set_title('Predictions', fontsize=12)\n",
    "ax.set_xlabel('Return (%)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis and Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"QUANTITATIVE ANALYSIS (Real Data)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for regime in regimes:\n",
    "    ds = norm_datasets[regime]\n",
    "    preds = predictions[regime]\n",
    "    \n",
    "    print(f\"\\n{regime.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  {'Metric':<25} {'Ground Truth':>15} {'Prediction':>15}\")\n",
    "    print(f\"  {'-'*55}\")\n",
    "    print(f\"  {'Mean Return':<25} {ds.targets.mean()*100:>+14.4f}% {preds.mean()*100:>+14.4f}%\")\n",
    "    print(f\"  {'Std Dev':<25} {ds.targets.std()*100:>14.4f}% {preds.std()*100:>14.4f}%\")\n",
    "    print(f\"  {'% Positive':<25} {(ds.targets>0).mean()*100:>14.1f}% {(preds>0).mean()*100:>14.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verdict\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "bullish_preds = predictions['bullish']\n",
    "bearish_preds = predictions['bearish']\n",
    "neutral_preds = predictions['neutral']\n",
    "\n",
    "# Criteria\n",
    "bullish_correct = bullish_preds.mean() > bearish_preds.mean() and (bullish_preds > 0).mean() > (bearish_preds > 0).mean()\n",
    "bearish_correct = bearish_preds.mean() < bullish_preds.mean() and (bearish_preds < 0).mean() > (bullish_preds < 0).mean()\n",
    "neutral_correct = bearish_preds.mean() < neutral_preds.mean() < bullish_preds.mean()\n",
    "means_different = bullish_preds.mean() - bearish_preds.mean() > 0.0005\n",
    "\n",
    "bullish_dir = (bullish_preds.mean() > 0) == (norm_datasets['bullish'].targets.mean() > 0)\n",
    "bearish_dir = (bearish_preds.mean() < 0) == (norm_datasets['bearish'].targets.mean() < 0)\n",
    "\n",
    "print(f\"\\nCriteria Check:\")\n",
    "print(f\"  [{'âœ“' if bullish_correct else 'âœ—'}] Bullish > Bearish\")\n",
    "print(f\"  [{'âœ“' if bearish_correct else 'âœ—'}] Bearish < Bullish\")\n",
    "print(f\"  [{'âœ“' if neutral_correct else 'âœ—'}] Neutral in between\")\n",
    "print(f\"  [{'âœ“' if means_different else 'âœ—'}] Distributions distinct\")\n",
    "print(f\"  [{'âœ“' if bullish_dir else 'âœ—'}] Bullish direction correct\")\n",
    "print(f\"  [{'âœ“' if bearish_dir else 'âœ—'}] Bearish direction correct\")\n",
    "\n",
    "all_pass = bullish_correct and bearish_correct and means_different\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "if all_pass:\n",
    "    print(\"\\nðŸŽ‰ [PASS] Model learned conditional distributions from real data!\")\n",
    "    print(f\"\\n  Bullish: {bullish_preds.mean()*100:+.4f}%\")\n",
    "    print(f\"  Bearish: {bearish_preds.mean()*100:+.4f}%\")\n",
    "    print(f\"  Neutral: {neutral_preds.mean()*100:+.4f}%\")\n",
    "elif bullish_dir and bearish_dir:\n",
    "    print(\"\\nâš ï¸  [PARTIAL] Model learned direction correctly\")\n",
    "else:\n",
    "    print(\"\\nâŒ [FAIL] Model did not learn distinct distributions\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_visualize(regime: str, n_samples: int = 500):\n",
    "    \"\"\"Sample from a regime and visualize.\"\"\"\n",
    "    if regime not in norm_datasets:\n",
    "        print(f\"Unknown regime: {regime}\")\n",
    "        return\n",
    "    \n",
    "    ds = norm_datasets[regime]\n",
    "    color = colors[regime]\n",
    "    \n",
    "    print(f\"Sampling {n_samples} predictions for {regime}...\")\n",
    "    preds = sample_regime(model, ds.get_condition_tensor(), n_samples=n_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.hist(ds.targets * 100, bins=40, alpha=0.5, label='Ground Truth', density=True)\n",
    "    ax.hist(preds * 100, bins=40, alpha=0.5, label='Predictions', density=True, color=color)\n",
    "    ax.axvline(x=0, color='black', linestyle='--')\n",
    "    ax.set_title(f'{regime.capitalize()} - Distribution')\n",
    "    ax.set_xlabel('Return (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.scatter(range(len(preds)), preds * 100, alpha=0.5, s=10, c=color)\n",
    "    ax.axhline(y=0, color='black', linestyle='--')\n",
    "    ax.axhline(y=ds.targets.mean() * 100, color='red', linewidth=2, label=f'GT: {ds.targets.mean()*100:+.4f}%')\n",
    "    ax.axhline(y=preds.mean() * 100, color='blue', linewidth=2, label=f'Pred: {preds.mean()*100:+.4f}%')\n",
    "    ax.set_title(f'{regime.capitalize()} - Samples')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Return (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"GT:   mean={ds.targets.mean()*100:+.4f}%, pos={(ds.targets>0).mean()*100:.1f}%\")\n",
    "    print(f\"Pred: mean={preds.mean()*100:+.4f}%, pos={(preds>0).mean()*100:.1f}%\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sample_and_visualize('bullish', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sample_and_visualize('bearish', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sample_and_visualize('neutral', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = {\n",
    "    'config': {\n",
    "        'seq_length': SEQ_LENGTH,\n",
    "        'horizon': HORIZON,\n",
    "        'n_samples_per_regime': N_SAMPLES_PER_REGIME,\n",
    "        'epochs': EPOCHS,\n",
    "        'return_threshold': float(threshold),\n",
    "        'data_source': 'real_stock_data'\n",
    "    },\n",
    "    'results': {\n",
    "        regime: {\n",
    "            'gt_mean': float(norm_datasets[regime].targets.mean()),\n",
    "            'gt_std': float(norm_datasets[regime].targets.std()),\n",
    "            'gt_pct_positive': float((norm_datasets[regime].targets > 0).mean() * 100),\n",
    "            'pred_mean': float(predictions[regime].mean()),\n",
    "            'pred_std': float(predictions[regime].std()),\n",
    "            'pred_pct_positive': float((predictions[regime] > 0).mean() * 100)\n",
    "        }\n",
    "        for regime in regimes\n",
    "    },\n",
    "    'final_loss': float(losses[-1]),\n",
    "    'verdict': {'all_pass': bool(all_pass)}\n",
    "}\n",
    "\n",
    "output_path = project_root / 'outputs' / 'real_regime_validation_results.json'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
